# WebScraper for Monster.com (Source : http://www.monsterindia.com/)

import requests
from bs4 import BeautifulSoup

r = requests.get("http://www.#PASTE_YOUR_URL/")
c = r.content

soup = BeautifulSoup(c, "html.parser")
beaut = BeautifulSoup.prettify(soup)

l = []
base_url = "http://www.#PASTE_YOUR_URL/-"     ::# Use - for looping through multiple pages. ex : base_url = "http://www.monsterindia.com/java-jobs-in-chennai-"    
for page in range(0,25,1):
    print(base_url+str(page)+".html")
    r = requests.get(base_url+str(page)+".html")
    c = r.content
    soup = BeautifulSoup(c,"html.parser")
    all = soup.find_all("div",{"type":"tuple"})
    for item in all:
        d = {}
        d["Company"] = item.find_all("div",{"class":"jtxt orange"})[0].text
        d["Title"] = item.find_all("h2",{"class":"seotitle"})[0].text
        try:
            d["Location"] = item.find_all("div",{"class":"jtxt jico ico1"})[0].text
        except:
            d["Location"] = None
        try:
            d["Experience"] = item.find_all("div",{"class":"jtxt jico ico2"})[0].text
        except:
            d["Experience"] = None
        l.append(d)
		

import pandas
df=pandas.DataFrame(l)

df.to_csv("#OutputName.csv")